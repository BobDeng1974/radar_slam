<launch>  
  <!-- Set to use simulated time -->
  <param name="use_sim_time" value="true" />	  

  <!-- Load YAML params and run the node to estimate the car pose and publish it -->
  <rosparam command="load" file="$(find radar_slam)/config/gps_pose_est.yaml" />
  <node name="gps_base_tf_broadcaster_node" output="screen" pkg="radar_slam" type="gps_base_tf_broadcaster_node" />

  <!-- Run the point cloud visualization nodes -->
  <node name="front_right_data_viz_node" output="screen" pkg="radar_ros_interface" type="radar_data_viz_point_cloud_node" args="--topic front_right_radar_data" />
  <node name="rear_left_data_viz_node" output="screen" pkg="radar_ros_interface" type="radar_data_viz_point_cloud_node" args="--topic rear_left_radar_data" />

  <!-- Run the laser scan nodes -->
  <node name="front_right_radar_data_to_laser_scan_node" output="screen" pkg="radar_ros_interface" type="radar_data_to_laser_scan_node" args="--topic front_right_radar_data" >
    <param name="angle_increment" value="0.01745" />
    <param name="range_min" value="2.0" />
  </node>
  <node name="rear_left_radar_data_to_laser_scan_node" output="screen" pkg="radar_ros_interface" type="radar_data_to_laser_scan_node" args="--topic rear_left_radar_data" >
    <param name="angle_increment" value="0.01745" />
    <param name="range_min" value="2.0" />
  </node>

  <!-- Load the car URDF for visualization and publish robot states -->
  <arg name="model" default="$(find radar_slam)/urdf/car_gps_test.urdf"/>
  <param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
  <node name="robot_state_publisher" pkg="robot_state_publisher" type="state_publisher" >
    <param name="publish_frequency" value="100" />
  </node>

  <!-- Run the car joint state publisher using car data -->
  <node name="car_joint_state_pub_node" pkg="radar_slam" type="car_joint_state_pub_node" output="screen" />
  <!-- <node name="joint_state_publisher" pkg="joint_state_publisher" type="joint_state_publisher" /> -->
  
  <!-- Republish compressed image data as decompressed image data, needed for tensorflow object detector -->
  <!-- <node name="republish" type="republish" pkg="image_transport" output="screen" args="compressed in:=/usb_cam/image_raw raw out:=/usb_cam/image_raw" /> -->

  <!-- Run tensorflow object detector. Make sure to source bin/activate in tensorflow env -->
  <!-- <node pkg= "tensorflow_object_detector" name="detect_ros" type="detect_ros.py"  output="screen">  -->
  <!--   <remap from="image" to="/usb_cam/image_raw"/> -->
  <!-- </node> -->
  <!-- <node pkg="image_view" type="image_view" name="image_view"> -->
  <!--   <remap from="image" to="debug_image"/> -->
  <!-- </node> -->
  
  <!-- Load the rviz configuration -->
  <arg name="rvizconfig_gps_pose_est" default="$(find radar_slam)/rviz/gps_pose_est.rviz" />

  <!-- Run rviz -->
  <node name="rviz_gps_pose_est" pkg="rviz" type="rviz" output="screen" args="-d $(arg rvizconfig_gps_pose_est)" />

  <!-- Run the node to publish car data messages -->
  <node pkg="rosbag" type="play" name="player" output="screen" args="--rate=2.0 --clock /home/nrotella/bagfiles/long.bag" />
  
</launch>
